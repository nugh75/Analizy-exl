#!/usr/bin/env python3
"""
Test per verificare che OpenAI sia stato completamente rimosso
"""

def test_no_openai_imports():
    """Verifica che non ci siano import di OpenAI"""
    print("üîç Verificando rimozione di OpenAI...")
    
    try:
        # Questo dovrebbe fallire
        from langchain_openai import ChatOpenAI
        print("‚ùå ERRORE: langchain_openai √® ancora presente!")
        return False
    except ImportError:
        print("‚úÖ langchain_openai rimosso correttamente")
    
    # Questi dovrebbero funzionare
    try:
        from langchain_ollama import OllamaLLM
        print("‚úÖ langchain_ollama funziona")
        
        import requests
        print("‚úÖ requests funziona")
        
        return True
    except ImportError as e:
        print(f"‚ùå Errore con altre librerie: {e}")
        return False

def test_openrouter_wrapper():
    """Testa la classe OpenRouterLLM personalizzata"""
    print("\nüîç Testando OpenRouterLLM wrapper...")
    
    class OpenRouterLLM:
        """Wrapper personalizzato per OpenRouter senza dipendere da OpenAI"""
        
        def __init__(self, model, api_key, temperature=0.7):
            self.model = model
            self.api_key = api_key
            self.temperature = temperature
            self.base_url = "https://openrouter.ai/api/v1/chat/completions"
        
        def invoke(self, messages):
            """Invoca il modello OpenRouter con i messaggi forniti"""
            # Test simulato
            return "Test response"
    
    try:
        llm = OpenRouterLLM(
            model="test-model",
            api_key="test-key",
            temperature=0.7
        )
        
        # Test con string input
        response1 = llm.invoke("test prompt")
        print(f"‚úÖ String input: {response1}")
        
        # Test con messages format
        response2 = llm.invoke([{"role": "user", "content": "test"}])
        print(f"‚úÖ Messages input: {response2}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Errore wrapper: {e}")
        return False

def test_env_configuration():
    """Testa la configurazione senza OpenAI"""
    print("\nüîç Testando configurazione environment...")
    
    import os
    from dotenv import load_dotenv
    load_dotenv()
    
    provider = os.getenv('AI_PROVIDER', 'ollama').lower()
    print(f"üìã Provider configurato: {provider}")
    
    if provider == 'openai':
        print("‚ùå ERRORE: Provider √® ancora impostato su OpenAI!")
        return False
    elif provider in ['ollama', 'openrouter']:
        print(f"‚úÖ Provider valido: {provider}")
        return True
    else:
        print(f"‚ö†Ô∏è  Provider sconosciuto: {provider}")
        return False

if __name__ == "__main__":
    print("üß™ TEST RIMOZIONE OPENAI")
    print("=" * 40)
    
    test1 = test_no_openai_imports()
    test2 = test_openrouter_wrapper()
    test3 = test_env_configuration()
    
    if all([test1, test2, test3]):
        print("\n‚úÖ TUTTI I TEST PASSATI!")
        print("üéâ OpenAI √® stato rimosso completamente!")
    else:
        print("\n‚ùå ALCUNI TEST FALLITI")
        print("‚ö†Ô∏è  Verifica i problemi sopra")
